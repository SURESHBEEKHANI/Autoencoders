{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SURESHBEEKHANI/Autoencoders/blob/main/Vanilla%20Autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autoencoders\n",
        "\n",
        "**Autoencoders** are a particular type of neural network, just like classifiers. Autoencoders are similar to classifiers in the sense that they compress data. However, where classifiers condense all the data of an image into a single label, autoencoders compress the data into a **latent vector**, often denoted $z$ in literature, with the goal of preserving the opportunity to recreate the exact same image in the future. Because autoencoders learn representations instead of labels, autoencoders belong to representation learning, a subfield of machine learning, but not necessarily deep learning.\n",
        "\n",
        "While recreating the same data from a compressed version might seem like an impossible task. However, _you_ can actually do the same. You probably have no difficulty memorizing the following sequence:\n",
        "\n",
        "$$1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27...$$\n",
        "\n",
        "I bet you haven't looked at every item, but you can still write down the sequence perfectly because you recognized a pattern: all uneven numbers, starting from 1.\n",
        "\n",
        "This is what autoencoders do: they find patterns in data.\n",
        "\n",
        "## Architecture\n",
        "Autoencoders consist of two networks:\n",
        "\n",
        "* Encoder\n",
        "* Decoder\n",
        "\n",
        "The goal of the **encoder** is to compress an image, video, or any piece of data that can be represented as a tensor, into a _latent vector_. The **decoder** does, as you might have guessed, the exact opposite.\n",
        "\n",
        "To maximize performance, minimize the loss that is, encoders and decoders are typically symmetrical together. Naturally, the input size is equal to the output size of an autoencoder.\n",
        "\n",
        "Autoencoders always have less input neurons in the middle layer than in the input and output layer. This is called the **bottleneck**. If it weren't for this bottleneck, the autoencoders could just copy this data over from the input to the output layer without compressing it.\n",
        "\n",
        "![](https://upload.wikimedia.org/wikipedia/commons/2/28/Autoencoder_structure.png) [source](https://en.wikipedia.org/wiki/File:Autoencoder_structure.png)\n",
        "\n",
        "## Training\n",
        "\n",
        "Encoders and decoders _can_ be trained separately, but usually they are trained in one go. In order to do so, one stacks the coders together in one **stacked autoencoder**.\n",
        "\n",
        "If one desires to train autoencoders separately, one starts by using the first hidden layer, discaring every other layer, except for the input and output layers of course. He uses the original training data at this point. Next, he uses the latent vector $z$ learnt by this mini-autoencoder and trains another autoencoder in the same way, treating the latent vectors as original data. Once the desired depth is reached, one can stack all output layers, which provided the latent vectors, together in a sinle encoder. This approach is not used in practise a lot, but literature might refer to it as greedy layerwise training so it's good to know what it means.\n",
        "\n",
        "## Appliciations\n",
        "\n",
        "While the phase \"finding patterns\" might not seem very interesting, there are a lot of exciting applications of autoencoders. We will look at three of those today:\n",
        "\n",
        "1. Dense autoencoder: compressing data.\n",
        "2. Convolutional autoencoder: a building block of DCGANs, self-supervised learning.\n",
        "3. Denoising autoencoder: removing noise from poor training data.\n",
        "\n",
        "While all of these applications use pattern finding, they have different use cases making autoencoders one of the most exciting topics of machine learning."
      ],
      "metadata": {
        "id": "gdKGuOgtu4yN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gr5ULVLKzkPQ"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the data\n",
        "\n",
        "We will load MNIST, but without labels because representation learning is **unsupervised**, or **self-supervised** which is the prefered"
      ],
      "metadata": {
        "id": "GiRwry2pvweM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load the dataset not use label in  we prisuction data we Generation\n",
        "(x_train, _),(x_test, _)=keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "YtRqU4rTGjSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#normilize the data range into [0,1]\n",
        "x_train=x_train/255.0\n",
        "x_test=x_test/255.0"
      ],
      "metadata": {
        "id": "kxK6xRC4HMJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A simple autoencoder\n",
        "\n",
        "Let's start by looking at the simplest possible autoencoder."
      ],
      "metadata": {
        "id": "kvLtIa-6v6kF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `encoder` is a sequential neural network with $28 \\times 28$ input neurons, $100$ neurons in the second layer and $30$ in the third. The third layer is called the \"bottleneck\". Feel free to play around with this variable to see how it affects results."
      ],
      "metadata": {
        "id": "-XQqLborv_rb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the simple autoencoder\n",
        "\n",
        "# Create the encoder part of the autoencoder\n",
        "encoder = keras.Sequential([\n",
        "    # Flatten the input image of shape 28x28 into a 1D array of 784 elements\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "\n",
        "    # First dense layer with 100 neurons and ReLU activation function\n",
        "    keras.layers.Dense(100, activation='relu'),\n",
        "\n",
        "    # Second dense layer with 30 neurons and ReLU activation function\n",
        "    keras.layers.Dense(30, activation='relu')\n",
        "])\n"
      ],
      "metadata": {
        "id": "6uhvWYoZHeOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create the decoder part of autoencoder\n",
        "decoder = keras.Sequential([\n",
        "\n",
        "    # Second dense layer with 100 neurons and ReLU activation function\n",
        "    keras.layers.Dense(100, activation='relu', input_shape=[30]),\n",
        "   # Flatten the output of the decoder into a 28x28 image\n",
        "   # First dense layer with 784 neurons and sigmoid activation function\n",
        "    keras.layers.Dense(784, activation='sigmoid'),\n",
        "    #Reshape the image\n",
        "    keras.layers.Reshape([28, 28])\n",
        "])"
      ],
      "metadata": {
        "id": "goU5XFv_KdCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bulid model in Sequential\n",
        "\n",
        "stacked_autoencoder = keras.Sequential([encoder, decoder])"
      ],
      "metadata": {
        "id": "uqxvvvK8JwnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that we use binary cross entropy loss in stead of categorical cross entropy. The reason for that is because we are not classifying latent vectors to belong to a particular class, we do not even have classes!, but rather are trying to predict whether a pixel should be activated or not."
      ],
      "metadata": {
        "id": "xOg91M4Nwg6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the optimizer with a specific learning rate\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "\n",
        "# Compile the stacked autoencoder model with the optimizer\n",
        "stacked_autoencoder.compile(optimizer=optimizer,\n",
        "                            loss='binary_crossentropy',  # Use appropriate loss function for reconstruction\n",
        "                            metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "stacked_autoencoder.summary()"
      ],
      "metadata": {
        "id": "DLwEhamKMTZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice how the $x$ and $y$, both $x$, `x_train` if you like, are equal:"
      ],
      "metadata": {
        "id": "xeDwQ8gGwr9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Train the model\n",
        "stacked_autoencoder.fit(x_train, x_train, epochs=15, batch_size=10 ,validation_data=[x_test, x_test])"
      ],
      "metadata": {
        "id": "KuR0sQDKNE_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming stacked_autoencoder is your trained autoencoder model\n",
        "# Assuming x_test contains your test data\n",
        "\n",
        "# Set the figure size\n",
        "plt.figure(figsize=(20, 5))\n",
        "\n",
        "# Loop through and plot original and reconstructed images\n",
        "for i in range(8):\n",
        "    # Original image\n",
        "    original = x_test[i].reshape(28, 28)\n",
        "\n",
        "    # Reconstructed image\n",
        "    reconstructed = stacked_autoencoder.predict(x_test[i].reshape(1, 28, 28))[0].reshape(28, 28)\n",
        "\n",
        "    # Plotting original image\n",
        "    plt.subplot(2, 8, i + 1)\n",
        "    plt.imshow(original, cmap='binary')  # Fixed cmap='binary' instead of 'binarry'\n",
        "    plt.title('Original')\n",
        "\n",
        "\n",
        "    # Plotting reconstructed image\n",
        "    plt.subplot(2, 8, 8 + i + 1)\n",
        "    plt.imshow(reconstructed, cmap='binary')  # Fixed cmap='binary' instead of 'binarry'\n",
        "    plt.title('Reconstructed')\n",
        "\n",
        "# Adjust layout and display plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Xi-xDfclwszy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the index of the image you want to visualize\n",
        "i = 0\n",
        "\n",
        "# Set up the figure and subplots\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Plot the original image\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(x_test[i], cmap='binary')\n",
        "plt.title('Original Image')\n",
        "\n",
        "\n",
        "# Plot the latent space representation\n",
        "plt.subplot(1, 3, 2)\n",
        "latent_space = encoder.predict(x_test[i].reshape(1, 28, 28))\n",
        "plt.imshow(latent_space, cmap='binary')  # Assuming latent_space shape is (1, 30)\n",
        "plt.title('Latent Space Representation')\n",
        "\n",
        "\n",
        "# Reconstruct the image from the latent space representation\n",
        "reconstructed = decoder.predict(latent_space)\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(reconstructed.reshape(28, 28), cmap='binary')\n",
        "plt.title('Reconstructed Image')\n",
        "\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tr5WQnaUyg1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wFNjeDxoyGzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate sparsity_lower: This calculates the proportion of zero elements in a 28x28 matrix\n",
        "# where 30 elements are zero.\n",
        "sparsity_lower = 30 / (28 * 28)\n",
        "\n",
        "# Calculate sparsity_higher: This calculates the proportion of non-zero elements in the same\n",
        "# 28x28 matrix.\n",
        "sparsity_higher = 1 - sparsity_lower\n",
        "\n",
        "# Display the results\n",
        "print(\"Sparsity Lower:\", sparsity_lower)\n",
        "print(\"Sparsity Higher:\", sparsity_higher)\n"
      ],
      "metadata": {
        "id": "scWG6v2y4n-I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}